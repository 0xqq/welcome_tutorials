{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TensorFlow tutorial\n",
    "_MILA, November 2017_\n",
    "\n",
    "## Protip: browsing through the TensorFlow API\n",
    "\n",
    "The [devdocs.io](http://devdocs.io/) website is an amazing resource to browse through the TensorFlow Python API (as well as many other APIs such as numpy or the Python API itself).\n",
    "\n",
    "# Using TensorFlow at MILA\n",
    "\n",
    "The most straightforward way to access TensorFlow using the MILA software stack is through the `TODO: WRITEME` conda environment. To activate the `TODO: WRITEME` environment, use the command\n",
    "\n",
    "```bash\n",
    "source activate TODO: WRITEME\n",
    "```\n",
    "\n",
    "To return back to normal, simply use the bash command\n",
    "\n",
    "```bash\n",
    "source deactivate\n",
    "```\n",
    "\n",
    "# Installing TensorFlow outside MILA\n",
    "\n",
    "Follow the [online documentation](https://www.tensorflow.org/install/), which describes how to install TensorFlow for all major platforms (Linux, macOS, Windows) in various ways (`virtualenv`, native `pip`, Docker, Anaconda).\n",
    "\n",
    "# Importing TensorFlow\n",
    "\n",
    "TensorFlow is imported as a Python package using the following statement:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Note: the `tensorflow` package is usually aliased to `tf` for convenience._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Paradigm\n",
    "\n",
    "TensorFlow separates the _definition_ of computation from its _execution_.\n",
    "\n",
    "Computation is defined via a [_dataflow_](https://en.wikipedia.org/wiki/Dataflow_programming) _graph_, i.e., a graph where nodes represent units of computation and the edges represent the data consumed or produced by the computation.\n",
    "\n",
    "TensorFlow calls these edges _tensors_ (not to be confused with the mathematical object of the same name). In TensorFlow parlance, a tensor is simply a multi-dimensional array of a certain data type.\n",
    "\n",
    "# Constant, variable, placeholder, and random tensors\n",
    "\n",
    "Many types of tensors may be used as input to the computation graph. We will cover four of them here: constant, variable, placeholder, and random tensors.\n",
    "\n",
    "## Constant\n",
    "\n",
    "A constant tensor always evaluates to the same value. It can be created using the `tf.constant` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"c:0\", shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "c = tf.constant(value=42.0, name='c')\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `name` argument is not strictly necessary, but it is considered good practice to name things in TensorFlow, as it facilitates visualizing the computation graph and debugging.\n",
    "\n",
    "To get the value associated with a constant tensor, we evaluate it within a session:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The value for c is 42.0\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as session:\n",
    "    print('The value for c is {}'.format(session.run(c)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The value for a constant _always_ stays the same, be it within the same session or across different sessions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The value for c is 42.0\n",
      "The value for c is 42.0\n",
      "The value for c is 42.0\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as session:\n",
    "    print('The value for c is {}'.format(session.run(c)))\n",
    "    print('The value for c is {}'.format(session.run(c)))\n",
    "\n",
    "with tf.Session() as session:\n",
    "    print('The value for c is {}'.format(session.run(c)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variable\n",
    "\n",
    "It can be useful for an input tensor's value to evolve across the lifetime of a session. For instance, a tensor's value can represent the weights of a neural network which we want to update using gradient descent.\n",
    "\n",
    "Tensors with this property are called _variables_. The preferred way to create variables is via `tf.get_variable`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.Variable 'v:0' shape=(2,) dtype=float32_ref>\n"
     ]
    }
   ],
   "source": [
    "v = tf.get_variable(\n",
    "    name='v', shape=[2], dtype=tf.float32,\n",
    "    initializer=tf.zeros_initializer())\n",
    "print(v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This time, the `name` argument is required. This is because TensorFlow refers to variables by name. As such, TensorFlow expects the name for the variable to be unique. Trying to create a variable with the same name will result in an error:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable v already exists, disallowed. Did you mean to set reuse=True in VarScope? Originally defined at:\n"
     ]
    }
   ],
   "source": [
    "# Throughout this tutorial, we will wrap statements that\n",
    "# we know will cause an error to be raised with a try-except\n",
    "# block to print the error message only, and not the whole\n",
    "# stack trace.\n",
    "try:\n",
    "    tf.get_variable(name='v')\n",
    "except ValueError as e:\n",
    "    print(str(e).split('\\n')[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_(In case you are wondering, there is a way to bypass this behavior and retrieve by name a variable which has already been created. More on that later.)_\n",
    "\n",
    "Note that a variable's value only makes sense _within the context of a session_. Furthermore, a variable's initial value has to be set before it can be used. See what happens if we try to evaluate `v` within a session:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempting to use uninitialized value v\n",
      "\t [[Node: _retval_v_0_0 = _Retval[T=DT_FLOAT, index=0, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](v)]]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as session:\n",
    "    try:\n",
    "        session.run(v)\n",
    "    except tf.errors.FailedPreconditionError as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TensorFlow provides a function, `tf.global_variables_initializer`, which returns an op that can be evaluated to do just that:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The value for v is [ 0.  0.]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as session:\n",
    "    session.run(tf.global_variables_initializer())\n",
    "    print('The value for v is {}'.format(session.run(v)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A variable's value persists across a session unless it is updated by running an assignment op. For instance, the op returned by `tf.assign_add` can be used to increment a variable's value:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The value for v is [ 0.  0.]\n",
      "The value for v is [ 0.  0.]\n",
      "The value for v is [ 1.  2.]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as session:\n",
    "    session.run(tf.global_variables_initializer())\n",
    "    # The value for v persists across session.run calls...\n",
    "    print('The value for v is {}'.format(session.run(v)))\n",
    "    print('The value for v is {}'.format(session.run(v)))\n",
    "    # ... until it is updated by running an assignment op.\n",
    "    session.run(v.assign_add([1, 2]))\n",
    "    print('The value for v is {}'.format(session.run(v)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition to `tf.assign_add`, the `tf.assign_sub` and `tf.assign` functions return ops which decrement and assign a variable's value, respectively.\n",
    "\n",
    "## Placeholder\n",
    "\n",
    "Oftentimes the computation we define depends on data which we don't yet have. For instance, the output of a neural network depends on a user-defined input which is only specified at runtime.\n",
    "\n",
    "_Placeholder_ tensors are used to represent this data. They can be created via `tf.placeholder`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"p:0\", shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "p = tf.placeholder(dtype=tf.float32, shape=[], name='p')\n",
    "print(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once again, the `name` argument is optional, but it is good practice to provide it.\n",
    "\n",
    "Because it has no pre-defined value, evaluating a placeholder tensor raises an error:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "InvalidArgumentError (see above for traceback): You must feed a value for placeholder tensor 'p' with dtype float\n",
      "\t [[Node: p = Placeholder[dtype=DT_FLOAT, shape=[], _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as session:\n",
    "    try:\n",
    "        session.run(p)\n",
    "    except tf.errors.InvalidArgumentError as e:\n",
    "        # Cutting through the error message...\n",
    "        print('\\n'.join(str(e).split('\\n')[-3:]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Its value must be _explicitly_ passed to `session.run` via the `feed_dict` argument, which expects a `dict` mapping tensors to their value:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The value for p is 42.0\n",
      "The value for p is 21.0\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as session:\n",
    "    # feed p the value 42\n",
    "    print('The value for p is {}'.format(session.run(p, feed_dict={p: 42})))\n",
    "    # feed p the value 21\n",
    "    print('The value for p is {}'.format(session.run(p, feed_dict={p: 21})))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random\n",
    "\n",
    "Another useful input tensor to have in our toolbox is the random tensor. The random seed can be set globally via `tf.set_random_seed`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.set_random_seed(1234)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are many random distributions to choose from in TensorFlow. Let's look at `tf.random_uniform`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "r = tf.random_uniform(\n",
    "    shape=[], minval=0.0, maxval=1.0, dtype=tf.float32, name='r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A random tensor's value changes randomly between `session.run` calls, but the sequence of those random values stays the same across different sessions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The value for r is 0.8478444814682007\n",
      "The value for r is 0.23446130752563477\n",
      "The value for r is 0.8478444814682007\n",
      "The value for r is 0.23446130752563477\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as session:\n",
    "    print('The value for r is {}'.format(session.run(r)))\n",
    "    print('The value for r is {}'.format(session.run(r)))\n",
    "\n",
    "with tf.Session() as session:\n",
    "    print('The value for r is {}'.format(session.run(r)))\n",
    "    print('The value for r is {}'.format(session.run(r)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combining tensors\n",
    "\n",
    "Tensors can be combined in various ways using what TensorFlow calls operations, or _ops_. Ops can take zero or more tensors as input and produce zero or more tensors as output, with our without side effects.\n",
    "\n",
    "We have already dealt with ops when initializing or assigning values to variables, but there are _many_ more TensorFlow functions which can be used to create ops.\n",
    "\n",
    "The best way to discover new useful ops is to browse the [TensorFlow Python API](https://www.tensorflow.org/api_docs/python/). For instance, we can discover that there exists a function, `tf.add`, which adds two tensors together and returns a tensor representing the output:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 + 3 = 4\n"
     ]
    }
   ],
   "source": [
    "one_plus_three = tf.add(1, 3)\n",
    "\n",
    "with tf.Session() as session:\n",
    "    print('1 + 3 = {}'.format(session.run(one_plus_three)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TensorFlow supports _automatic differentiation_, i.e., it can compute the derivative of scalars with respect to tensors in the graph and represent the result as a symbolic expression.\n",
    "\n",
    "Take for instance the linear equation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = tf.placeholder(dtype=tf.float32, shape=[], name='p')\n",
    "y = 3 * x + 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can compute the derivative of `y` with respect to `x` with the `tf.gradients` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dy_dx, = tf.gradients(ys=y, xs=[x])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can verify that the gradient evaluates to 3 as expected:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The gradient of y with respect to x is 3.0\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as session:\n",
    "    dy_dx_val = session.run(dy_dx)\n",
    "    print('The gradient of y with respect '\n",
    "          'to x is {}'.format(dy_dx_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Note: Some of you may have noticed that TensorFlow did not complain despite no value being provided for the `x` placeholder. This is because even though `x` is part of the computation graph, the derivative of `y` with respect to `x` does not involve `x`, and therefore evaluating it does not require a value to be passed for `x`._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise\n",
    "\n",
    "Find the minimum of the expression\n",
    "\n",
    "$$2(x - 2)^2 + 2(y + 3)^2$$\n",
    "\n",
    "using gradient descent by filling in the following code block:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.Graph().as_default():\n",
    "    tf.set_random_seed(1234)\n",
    "\n",
    "    # Create two scalar variables, x and y, initialized at random.\n",
    "    # x = WRITEME.\n",
    "    # y = WRITEME.\n",
    "\n",
    "    # Create a tensor z whose value represents the expression\n",
    "    #     2(x - 2)^2 + 2(y + 3)^2\n",
    "    # z = WRITEME.\n",
    "    \n",
    "    # Compute the gradients of z with respect to x and y.\n",
    "    # dx, dy = WRITEME.\n",
    "    \n",
    "    # Create an assignment expression for x using the update rule\n",
    "    #    x <- x - 0.1 * dz/dx\n",
    "    # and do the same for y.\n",
    "    # x_update = WRITEME.\n",
    "    # y_update = WRITEME.\n",
    "    \n",
    "    with tf.Session() as session:\n",
    "        # Run the global initializer op for x and y.\n",
    "        # WRITEME.\n",
    "        \n",
    "        for _ in range(10):\n",
    "            pass\n",
    "            # Run the update ops for x and y.\n",
    "            # WRITEME.\n",
    "            \n",
    "            # Retrieve the values for x, y, and z, and print them.\n",
    "            # x_val, y_val, z_val = WRITEME.\n",
    "            # print('x = {:4.2f}, y = {:4.2f}, z = {:4.2f}'.format(x_val, y_val, z_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x = 0.72, y = -1.62, z = 7.10\n",
      "x = 1.23, y = -2.17, z = 2.55\n",
      "x = 1.54, y = -2.50, z = 0.92\n",
      "x = 1.72, y = -2.70, z = 0.33\n",
      "x = 1.83, y = -2.82, z = 0.12\n",
      "x = 1.90, y = -2.89, z = 0.04\n",
      "x = 1.94, y = -2.94, z = 0.02\n",
      "x = 1.96, y = -2.96, z = 0.01\n",
      "x = 1.98, y = -2.98, z = 0.00\n",
      "x = 1.99, y = -2.99, z = 0.00\n"
     ]
    }
   ],
   "source": [
    "with tf.Graph().as_default():\n",
    "    tf.set_random_seed(1234)\n",
    "\n",
    "    # Create two scalar variables, x and y, initialized at random.\n",
    "    x = tf.get_variable(name='x', shape=[], dtype=tf.float32,\n",
    "                        initializer=tf.random_normal_initializer())\n",
    "    y = tf.get_variable(name='y', shape=[], dtype=tf.float32,\n",
    "                        initializer=tf.random_normal_initializer())\n",
    "\n",
    "    # Create a tensor z whose value represents the expression\n",
    "    #     2(x - 2)^2 + 2(y + 3)^2\n",
    "    z = 2 * (x - 2) ** 2 + 2 * (y + 3) ** 2\n",
    "    \n",
    "    # Compute the gradients of z with respect to x and y.\n",
    "    dx, dy = tf.gradients(z, [x, y])\n",
    "    \n",
    "    # Create an assignment expression for x using the update rule\n",
    "    #    x <- x - 0.1 * dz/dx\n",
    "    # and do the same for y.\n",
    "    x_update = tf.assign_sub(x, 0.1 * dx)\n",
    "    y_update = tf.assign_sub(y, 0.1 * dy)\n",
    "    \n",
    "    with tf.Session() as session:\n",
    "        # Run the global initializer op for x and y.\n",
    "        session.run(tf.global_variables_initializer())\n",
    "        \n",
    "        for _ in range(10):\n",
    "            # Run the update ops for x and y.\n",
    "            session.run([x_update, y_update])\n",
    "            \n",
    "            # Retrieve the values for x, y, and z, and print them.\n",
    "            x_val, y_val, z_val = session.run([x, y, z])\n",
    "            print('x = {:4.2f}, y = {:4.2f}, z = {:4.2f}'.format(x_val, y_val, z_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimization made easy\n",
    "\n",
    "The solution to the exercise above can be shortened quite a bit by taking advantage of TensorFlow's optimization features. Here is the graph we were working with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.set_random_seed(1234)\n",
    "x = tf.get_variable(name='x', shape=[], dtype=tf.float32,\n",
    "                    initializer=tf.random_normal_initializer())\n",
    "y = tf.get_variable(name='y', shape=[], dtype=tf.float32,\n",
    "                    initializer=tf.random_normal_initializer())\n",
    "\n",
    "z = 2 * (x - 2) ** 2 + 2 * (y + 3) ** 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TensorFlow provides utility classes to facilitate optimization in computation graphs. These classes inherit from `tf.train.Optimizer`. Let's look at the simplest one, `tf.train.GradientDescentOptimizer`.\n",
    "\n",
    "We instantiate the `tf.train.GradientOptimizer` by passing it a scalar learning rate. Note that the learning rate itself can be symbolic, and is allowed to vary across a session."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then call the optimizer's `minimize` function to obtain an op with, when evaluated, does a gradient descent step on the variables we specified:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "update_op = optimizer.minimize(loss=z, var_list=tf.trainable_variables())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we took advantage of the fact that all variables created via `tf.get_variable` can be accessed as a list using the `tf.trainable_variables` function.\n",
    "\n",
    "(Note: you can pass `trainable=False` to `tf.get_variable` to exclude a certain variable from ending up in that list.)\n",
    "\n",
    "The code then proceeds as before:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x = 0.21, y = -1.30, z = 12.17\n",
      "x = 0.93, y = -1.98, z = 4.38\n",
      "x = 1.36, y = -2.39, z = 1.58\n",
      "x = 1.61, y = -2.63, z = 0.57\n",
      "x = 1.77, y = -2.78, z = 0.20\n",
      "x = 1.86, y = -2.87, z = 0.07\n",
      "x = 1.92, y = -2.92, z = 0.03\n",
      "x = 1.95, y = -2.95, z = 0.01\n",
      "x = 1.97, y = -2.97, z = 0.00\n",
      "x = 1.98, y = -2.98, z = 0.00\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as session:\n",
    "    session.run(tf.global_variables_initializer())\n",
    "\n",
    "    for _ in range(10):\n",
    "        session.run(update_op)\n",
    "        x_val, y_val, z_val = session.run([x, y, z])\n",
    "        print('x = {:4.2f}, y = {:4.2f}, z = {:4.2f}'.format(x_val, y_val, z_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Control flow\n",
    "\n",
    "**TODO: WRITEME**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scaling up to large computation graphs\n",
    "\n",
    "We have now covered the bare minimum that would allow you to do machine learning with TensorFlow. We have not covered _every_ TensorFlow op, but you now possess the knowledge required to browse through the [TensorFlow Python API](https://www.tensorflow.org/api_docs/python/) and find what you need.\n",
    "\n",
    "We will now concentrate on ways to scale what you learned to actual machine learning problems without increasing the maintenance complexity too much.\n",
    "\n",
    "## Variable and name scopes\n",
    "\n",
    "TensorFlow uses a soft convention for op and variable names: an op or variable that is part of a hierarchy should have a name that conveys its location in the hierarchy, with the `'/'` character being used to separate different levels in the hierarchy. For instance, a good name for the bias vector of the second layer of the model would be `'model/layer2/b'`.\n",
    "\n",
    "In order to reduce code duplication and facilitate maintenance, TensorFlow provides two context managers, named `tf.name_scope` and `tf.variable_scope`, inside which variables and ops that are created see their name prepended with the name of the enclosing scope. The difference between the two is that `tf.variable_scope` operates on _all_ names, whereas `tf.name_scope` operates on all _but_ variable names:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "foo/bar/a:0\n",
      "foo/bar/b:0\n",
      "a:0\n",
      "machine/learning/b:0\n"
     ]
    }
   ],
   "source": [
    "# Variable scopes operate on all tensors\n",
    "with tf.variable_scope('foo'):\n",
    "    # Scopes can be nested\n",
    "    with tf.variable_scope('bar'):\n",
    "        print(tf.get_variable('a', shape=[]).name)\n",
    "        print(tf.constant(0.0, name='b').name)\n",
    "# Name scopes do not operate on variables\n",
    "with tf.name_scope('machine'):\n",
    "    with tf.name_scope('learning'):\n",
    "        print(tf.get_variable('a', shape=[]).name)\n",
    "        print(tf.constant(0.0, name='b').name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graph visualization with TensorBoard\n",
    "\n",
    "**TODO: WRITEME**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
